import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

st.set_page_config(page_title="Smart Grid Analytics", layout="wide", page_icon="ğŸ“Š")

# Simple header
st.title("ğŸ“Š Smart Grid Big Data Analytics")
st.subheader("Machine Learning for Energy Data Analysis")

# Generate simple sample data
@st.cache_data
def create_sample_data():
    np.random.seed(42)
    n_samples = 800
    
    data = {
        'voltage': np.random.normal(230, 15, n_samples),
        'current': np.random.normal(45, 10, n_samples), 
        'power': np.random.normal(10000, 2500, n_samples),
        'frequency': np.random.normal(50, 1, n_samples),
        'temperature': np.random.normal(25, 8, n_samples),
        'load_demand': np.random.normal(8000, 2000, n_samples)
    }
    return pd.DataFrame(data)

# Sidebar controls
st.sidebar.header("ğŸ›ï¸ Controls")

use_sample = st.sidebar.checkbox("ğŸ“Š Use Sample Data", value=True)

if use_sample:
    df = create_sample_data()
    st.sidebar.success("âœ… Sample data loaded")
    
    # Sample data information (like previous experiments)
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“‹ Sample Data Includes")
    st.sidebar.markdown("""
    **âš¡ Electrical Parameters:**
    â€¢ Voltage: 230V Â± 15V variations
    â€¢ Current: 45A Â± 10A fluctuations
    â€¢ Frequency: 50Hz Â± 1Hz stability
    
    **ğŸ­ Load Characteristics:**
    â€¢ Power: 10kW Â± 2.5kW consumption
    â€¢ Load Demand: 8kW Â± 2kW requests
    â€¢ Temperature: 25Â°C Â± 8Â°C ambient
    
    **ğŸ“Š Dataset Size:** 800 smart meter readings
    """)
    
else:
    uploaded_file = st.sidebar.file_uploader("Upload CSV", type=["csv"])
    if uploaded_file:
        df = pd.read_csv(uploaded_file)
    else:
        st.info("ğŸ‘† Please upload a CSV file or use sample data")
        st.stop()

# Show basic data info
st.markdown("## ğŸ“‹ Data Overview")
col1, col2, col3 = st.columns(3)
with col1:
    st.metric("ğŸ“Š Total Rows", len(df))
with col2:
    st.metric("ğŸ“ˆ Columns", len(df.columns))
with col3:
    st.metric("ğŸ”¢ Numeric Features", len(df.select_dtypes(include=[np.number]).columns))

# Data preview section (NEW)
st.markdown("### ğŸ‘€ Data Preview")
st.dataframe(df.head(10), use_container_width=True)

# Basic statistics (NEW)
st.markdown("### ğŸ“Š Data Statistics")
st.dataframe(df.describe().round(2), use_container_width=True)

# Feature selection
numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()
selected_features = st.sidebar.multiselect(
    "ğŸ¯ Select Features:", 
    numeric_features, 
    default=numeric_features[:4],
    help="Choose features for analysis"
)

# ML parameters
num_clusters = st.sidebar.slider("ğŸ¯ Number of Clusters", 2, 8, 4)

# Additional sidebar info (like previous experiments)
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ¤– Machine Learning Pipeline")
st.sidebar.markdown("""
â€¢ **Data Preprocessing:** Clean and standardize
â€¢ **PCA Analysis:** Reduce to 2D visualization  
â€¢ **K-Means Clustering:** Group similar patterns
â€¢ **Results Visualization:** Interactive scatter plots
""")

# Main analysis
if st.sidebar.button("ğŸš€ Run Analysis", type="primary") and len(selected_features) >= 2:
    
    # Prepare data
    data_clean = df[selected_features].dropna()
    
    # Step 1: Standardize data
    scaler = StandardScaler()
    data_scaled = scaler.fit_transform(data_clean)
    
    # Step 2: PCA (reduce to 2D)
    pca = PCA(n_components=2)
    pca_result = pca.fit_transform(data_scaled)
    
    # Step 3: Clustering
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    clusters = kmeans.fit_predict(data_scaled)
    
    # Results
    results_df = pd.DataFrame({
        'PC1': pca_result[:, 0],
        'PC2': pca_result[:, 1], 
        'Cluster': clusters
    })
    
    # Show key metrics
    st.markdown("## ğŸ¯ Analysis Results")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ğŸ” Features Analyzed", len(selected_features))
    with col2:
        variance_explained = sum(pca.explained_variance_ratio_) * 100
        st.metric("ğŸ“Š Variance Explained", f"{variance_explained:.1f}%")
    with col3:
        st.metric("ğŸ¯ Clusters Found", num_clusters)
    
    # Main visualization - PCA Scatter Plot
    st.markdown("### ğŸ¨ Customer Segmentation Results")
    
    fig = px.scatter(
        results_df, 
        x='PC1', y='PC2', 
        color='Cluster',
        title="ğŸ¯ Smart Grid Customer Clusters (PCA Visualization)",
        color_continuous_scale="viridis"
    )
    fig.update_layout(height=500, template="plotly_white")
    fig.update_traces(marker=dict(size=8, opacity=0.7))
    st.plotly_chart(fig, use_container_width=True)
    
    # Cluster summary
    st.markdown("### ğŸ“Š Cluster Analysis")
    cluster_data = data_clean.copy()
    cluster_data['Cluster'] = clusters
    cluster_summary = cluster_data.groupby('Cluster').mean().round(2)
    
    st.dataframe(cluster_summary, use_container_width=True)
    
    # Show sample results
    st.markdown("### ğŸ“‹ Sample Results with Cluster Assignments")
    sample_results = results_df.head(15).copy()
    sample_results['PC1'] = sample_results['PC1'].round(3)
    sample_results['PC2'] = sample_results['PC2'].round(3)
    st.dataframe(sample_results, use_container_width=True)

else:
    if len(selected_features) < 2:
        st.warning("âš ï¸ Please select at least 2 features")
    
    st.markdown("## ğŸ‘ˆ Configure settings and click 'Run Analysis'")
    st.markdown("### ğŸ¯ What this does:")
    st.markdown("""
    - **ğŸ” Data Analysis**: Analyze smart grid energy consumption patterns
    - **ğŸ“Š PCA**: Reduce complex data to 2D for visualization  
    - **ğŸ¯ Clustering**: Group similar customers automatically
    - **ğŸ“ˆ Insights**: Identify different types of energy users
    """)
